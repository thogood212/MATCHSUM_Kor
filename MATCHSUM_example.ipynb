{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MATCHSUM_Kor version\n",
        "\n",
        "-Extractive Summarization as Text Matching([paper](https://https://arxiv.org/pdf/2004.08795.pdf))\n",
        "\n",
        "##- Dependencies\n",
        "\n",
        "- kobert-transformers           0.5.1\n",
        "- transformers                  4.25.1\n",
        "- konlpy                        0.6.0(mecab)\n",
        "- pytorch-metric-learning       1.6.3\n",
        "- torch                         1.13.0\n",
        "\n",
        "##- Data\n",
        "AI-HUB 문서요약 텍스트(신문기사, 기고문, 잡지기사, 법원 판결문 원문, 요약 3문장)[Link]((https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=97))\n",
        "\n",
        "##- 설명\n",
        "\n",
        "- 본 코랩파일은 간단하게 구동할 수 있도록 정리되어있습니다. 예시로 봐주세요.\n",
        "\n",
        "### - 시작하기 전에\n",
        "- kor_rouge_metric.py 파일이 필요합니다. github에서 다운받은 후 구글 드라이브에 업로드하여 저장경로를 입력해주세요.\n",
        "- matchsum 모델은 사전에 요약모델을 사용한 pruning 과정이 필요합니다. 즉, 요약할 문서에서 중요한 문장 5개의 인덱스가 저장되어 있는 파일이 필요합니다.(없는 경우 제가 생성한 예시파일을 [이곳](https://drive.google.com/file/d/1-WOL5LUwQW4srDMMBJS6HP0FZBt3EYg9/view?usp=share_link)에서 다운로드(약 600MB)하여 사용해주세요.)"
      ],
      "metadata": {
        "id": "qB0L_V8_mLDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#경로 설정\n",
        "rouge_path = 'kor_rouge_metric.py 파일 경로' #ex)'/content/drive/MyDrive/matchsum'\n",
        "data_path = 'data 파열 경로(.json)' #ex)'/content/drive/MyDrive/matchsum/prun_data.json'\n",
        "output_dir = '모델 savepoint 경로' #ex)'/content/drive/MyDrive/matchsum/savepoint'\n",
        "model_path = 'model weight 경로' #ex)'/content/drive/MyDrive/matchsum/model/test_model_5.pt'"
      ],
      "metadata": {
        "id": "fVQkLtBjdMmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZKJRS6Iblddu"
      },
      "outputs": [],
      "source": [
        "#kor_rouge_metric를 사용하기 위해 path 추가\n",
        "import sys\n",
        "sys.path.append(rouge_path) # kor_rouge_metric.py 저장 경로를 입력해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIp6XjV3lfPV"
      },
      "outputs": [],
      "source": [
        "#mecab 설치\n",
        "!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "mecab = Mecab()\n",
        "mecab.morphs('동해물과 백두산이 마르고 닳도록')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2pymMXfllSw"
      },
      "outputs": [],
      "source": [
        "!pip install kobert_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S78srW9Ml4C5"
      },
      "outputs": [],
      "source": [
        "#Metric base\n",
        "!pip install pytorch_metric_learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZchYvAAFq3TN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from kor_rouge_metric import Rouge #py 파일이 별도로 필요\n",
        "from transformers import BertModel\n",
        "from kobert_transformers import get_tokenizer\n",
        "from pytorch_metric_learning.losses import BaseMetricLossFunction\n",
        "from torch.optim import Adam, AdamW\n",
        "from transformers import EarlyStoppingCallback, TrainingArguments,Trainer\n",
        "import os\n",
        "from os.path import join\n",
        "from time import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from datetime import timedelta\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_SCejVulnGR"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer() #kobert의 토크나이저\n",
        "bert_model = BertModel.from_pretrained('monologg/kobert')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEaHoo5Dlj0l"
      },
      "source": [
        "#Candidates Pruning\n",
        "KoBERTSUM 사용\n",
        "(https://github.com/uoneway/KoBertSum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8evtzTKcF8lq"
      },
      "source": [
        "# Candidate combination\n",
        "\n",
        "- custom dataset을 사용하여 candidate하는 경우 이 부분을 실행해주세요."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#초기 설정\n",
        "data = #데이터프레임 형태의 데이터\n",
        "tokenizer = get_tokenizer() #kobert의 토크나이저\n",
        "save_path = #pruning된 데이터 저장할 경로"
      ],
      "metadata": {
        "id": "HCTbj3iJfVc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "0czwwoycSwCr"
      },
      "outputs": [],
      "source": [
        "Final_rouge = Rouge(\n",
        "            metrics=[\"rouge-n\", \"rouge-l\"],\n",
        "            max_n=2,\n",
        "            limit_length=True,\n",
        "            length_limit=1000,\n",
        "            length_limit_type=\"words\",\n",
        "            use_tokenizer=True,\n",
        "            apply_avg=True,\n",
        "            apply_best=False,\n",
        "            alpha=0.5,  # Default F1_score\n",
        "            weight_factor=1.2,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "OzZbxCY2MXmF"
      },
      "outputs": [],
      "source": [
        "#get_candidate\n",
        "from itertools import combinations\n",
        "\n",
        "def get_candidates(tokenizer, idx,df):\n",
        "    MAX_LEN=180\n",
        "    MAX_LEN_text = 512\n",
        "\n",
        "    # load data\n",
        "    data = {}\n",
        "    #original text data\n",
        "    data['text'] = df.loc[idx]['src_txt']\n",
        "    #gold summary\n",
        "    data['summary'] = df.loc[idx]['abstractive']\n",
        "\n",
        "    # get candidate summaries\n",
        "    #각각 문서에서 5개의 중요한 문장을 truncate합니다.(using koBertSum)\n",
        "    # 2,3개의 문장을 선택하여 combinations을 사용하여 C(5,2)+C(5,3)=20 총 20개의 후보군 요약문을 생성합니다.\n",
        "    # 본 모델은 기본적으로 koBertSum 모델을 사전에 활용하여야 get candidate를 할 수 있습니다.\n",
        "    # 데이터프레임(df)에 ['sum_sents_idxes']열에 5개의 문장인덱스가 존재해야합니다.\n",
        "    #pruned text(5) index\n",
        "    sent_id = df.loc[idx]['sum_sents_idxes']\n",
        "    indices = list(combinations(sent_id, 2))\n",
        "    indices += list(combinations(sent_id, 3))\n",
        "    sep = '[SEP]'\n",
        "    sep_id = tokenizer.encode(sep, add_special_tokens=False)\n",
        "\n",
        "    # get ROUGE score for each candidate summary and sort them in descending order\n",
        "    score = []\n",
        "    for i in indices:\n",
        "        i = list(i)\n",
        "        i.sort()\n",
        "\n",
        "        # write dec\n",
        "        dec = []\n",
        "        for j in i:\n",
        "            sent = data['text'][j]\n",
        "            dec.append(sent)\n",
        "        #dec는 candidate summary당 문장 모음\n",
        "        rouge = Final_rouge.get_scores(df.loc[idx]['sum_sents_tokenized'], dec)\n",
        "\n",
        "        rouge1 = float(rouge['rouge-1']['f'])\n",
        "        rouge2 = float(rouge['rouge-2']['f'])\n",
        "        rougel = float(rouge['rouge-l']['f'])\n",
        "        rouge = (rouge1 + rouge2 + rougel) / 3\n",
        "        score.append((i, rouge))\n",
        "        \n",
        "    score.sort(key=lambda x : x[1], reverse=True)\n",
        "    \n",
        "    # write candidate indices and score\n",
        "    data['ext_idx'] = sent_id\n",
        "    data['indices'] = []\n",
        "    data['score'] = []\n",
        "    for i, R in score:\n",
        "        data['indices'].append(list(map(int, i)))\n",
        "        data['score'].append(R)\n",
        "\n",
        "    # tokenize and get candidate_id\n",
        "    candidate_summary = []\n",
        "    for i in data['indices']:\n",
        "        cur_summary = []\n",
        "        for j in i:\n",
        "            cur_summary.append(data['text'][j])\n",
        "        cur_summary = ' '.join(cur_summary)\n",
        "        candidate_summary.append(cur_summary)\n",
        "        \n",
        "    data['candidate_summary'] = candidate_summary\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8eHq1aZo93o",
        "outputId": "5157cf9f-b855-4aa6-a4a2-846438601881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0processing time : 0:00:00.459500 sec\n",
            "1000processing time : 0:04:17.681429 sec\n",
            "2000processing time : 0:08:02.693164 sec\n",
            "3000processing time : 0:11:37.180689 sec\n",
            "4000processing time : 0:15:15.015369 sec\n",
            "5000processing time : 0:18:49.685857 sec\n",
            "6000processing time : 0:22:26.528919 sec\n",
            "7000processing time : 0:26:10.695462 sec\n",
            "8000processing time : 0:29:57.360230 sec\n",
            "9000processing time : 0:33:41.452856 sec\n",
            "10000processing time : 0:37:31.184223 sec\n",
            "11000processing time : 0:41:26.886138 sec\n",
            "12000processing time : 0:45:29.492182 sec\n",
            "13000processing time : 0:49:27.924716 sec\n",
            "14000processing time : 0:53:22.644642 sec\n",
            "15000processing time : 0:57:16.140237 sec\n",
            "16000processing time : 1:01:05.287196 sec\n",
            "17000processing time : 1:05:12.737635 sec\n",
            "18000processing time : 1:09:17.862427 sec\n",
            "19000processing time : 1:13:19.831756 sec\n",
            "20000processing time : 1:17:18.421368 sec\n",
            "21000processing time : 1:21:24.934761 sec\n",
            "end time : 1:21:24.934761 sec\n"
          ]
        }
      ],
      "source": [
        "# 데이터에서 candidate를 실행\n",
        "import time\n",
        "import datetime\n",
        "prun_data = []\n",
        "\n",
        "start = time.time() \n",
        "for idx in range(len(data)):\n",
        "    prun_data.append(get_candidates(tokenizer,idx,data))\n",
        "    if idx%1000 ==0:\n",
        "      sec = time.time()-start # 종료 - 시작 (걸린 시간)\n",
        "      times = str(datetime.timedelta(seconds=sec))\n",
        "      print(f\"{idx}processing time : {times} sec\")\n",
        "times = str(datetime.timedelta(seconds=sec))\n",
        "print(f\"end time : {times} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "btdfnIvHNUXz",
        "outputId": "bff4c840-4a1a-448e-e127-513357edc856"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9a4aa08f-fa90-4713-991a-a7b97f5629ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src_txt</th>\n",
              "      <th>tgt_txt</th>\n",
              "      <th>sum_sents_tokenized</th>\n",
              "      <th>sum_sents_idxes</th>\n",
              "      <th>abstractive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[대한민국 5 G 홍보 대사 를 자처 한 문재 인 대통령 은 넓 고 체증 없 는 통...</td>\n",
              "      <td>대한민국 5 G 홍보 대사 를 자처 한 문재 인 대통령 은 넓 고 체증 없 는 통신...</td>\n",
              "      <td>문 대통령 은 8 일 서울 올림픽 공원 에서 열린 5 G 플러스 전략 발표 에 참석...</td>\n",
              "      <td>[1, 0, 9, 6, 4]</td>\n",
              "      <td>[8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[8 일 서울 올림픽 공원 K 아트홀, 지난 3 일 한국 이 세계 최초 로 5 세대...</td>\n",
              "      <td>지난 3 일 한국 이 세계 최초 로 5 세대 5 G 이동 통신 서비스 를 상용 화 ...</td>\n",
              "      <td>8 일 서울 올림픽 공원 K 아트홀\\n문재인 대통령 홍남기 부총리 겸 기획 재정부 ...</td>\n",
              "      <td>[0, 8, 10, 6, 1]</td>\n",
              "      <td>[지난 3일 한국이 세계 첫 5세대 이동통신 서비스를 보편화한 것을 축하하는 '코리...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[] 박원순 서울 시장 사진 이 8 일 고층 재 개발 재건축 관련 요구 에 작심 한...</td>\n",
              "      <td>] 박원순 서울 시장 사진 이 8 일 고층 재 개발 재건축 관련 요구 에 작심 한 ...</td>\n",
              "      <td>박 시장 은 이날 서울 시청 에서 열린 골목길 재생 시민 정책 대화 에 참석 해 과...</td>\n",
              "      <td>[1, 0, 4, 3, 5]</td>\n",
              "      <td>[박원순 서울시장은 8일 서울시청에서 열린 '골목길 재생 시민 정책 대화'에 참석하...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[SK 주 와 미국 알파벳 구글 지주회사 의 간결 한 지배 구조 를 배워라, 기업 ...</td>\n",
              "      <td>기업 지배 구조 개선 등 을 통해 높 은 수익 률 을 올리 는 것 을 목표 로 하 ...</td>\n",
              "      <td>SK 주 와 미국 알파벳 구글 지주회사 의 간결 한 지배 구조 를 배워라\\nKB 운...</td>\n",
              "      <td>[0, 2, 1, 7, 9]</td>\n",
              "      <td>[주주가치 포커스를 운용하는 KB자산운용이  SK와 알파벳(구글 지주회사)의 모범적...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[MBC 당신 이 믿 었 던 페이크 가 JTBC 손석희 대표 이사 의 동승자 논란 ...</td>\n",
              "      <td>MBC 당신 이 믿 었 던 페이크 가 JTBC 손석희 대표 이사 의 동승자 논란 진...</td>\n",
              "      <td>MBC 당신 이 믿 었 던 페이크 가 JTBC 손석희 대표 이사 의 동승자 논란 진...</td>\n",
              "      <td>[0, 8, 10, 9, 5]</td>\n",
              "      <td>[MBC ' 당신이 믿었던 페이크' 가 JTBC 손석희 대표의 '동승자 논란' 진실...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21301</th>\n",
              "      <td>[울릉도 명이 가 유명세 를 탈 전망 이 다, 29 일 한국 을 공식 방문 한 도널...</td>\n",
              "      <td>울릉도 명이 가 유명세 를 탈 전망 이 다&lt;q&gt;29 일 한국 을 공식 방문 한 도널...</td>\n",
              "      <td>29 일 한국 을 공식 방문 한 도널드 트럼프 대통령 의 청와대 친교 만찬 에 경북...</td>\n",
              "      <td>[1, 2, 0, 9, 8]</td>\n",
              "      <td>[포항시는 오는 7월 당초 109개 노선 200대 운행에서 119개 노선 270대로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21302</th>\n",
              "      <td>[경기도 수원 의 카페 투어 를 소재 로 한 토크 쇼 가 일본 의 수도 도쿄 에서 ...</td>\n",
              "      <td>경기도 와 경기 관광공사 는 지난 29 일 일본 도쿄 에서 경기도 골목 의 카페 와...</td>\n",
              "      <td>경기도 와 경기 관광공사 는 지난 29 일 일본 도쿄 에서 경기도 골목 의 카페 와...</td>\n",
              "      <td>[1, 0, 8, 6, 9]</td>\n",
              "      <td>[경북울릉군 특산물인 명이장아찌가 2017년 한·미 정상회담 독도새우에 이어 29일...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21303</th>\n",
              "      <td>[산업은행 은 다음 달 23 24 일 이틀 간 서울 강남구 코엑스 에서 넥스트 라이...</td>\n",
              "      <td>산업은행 은 다음 달 23 24 일 이틀 간 서울 강남구 코엑스 에서 넥스트 라이즈...</td>\n",
              "      <td>산업은행 은 다음 달 23 24 일 이틀 간 서울 강남구 코엑스 에서 넥스트 라이즈...</td>\n",
              "      <td>[0, 7, 8, 10, 1]</td>\n",
              "      <td>[지난 해 일본어 핸드 가이드 북인 '수원 카페북(마루마루 수원)이 투어리즘 엑스포...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21304</th>\n",
              "      <td>[경기도 는 집배원 택배 기사 등 이동 노동자 들 을 위한 폭염 대책 의 하나 로 ...</td>\n",
              "      <td>경기도 는 집배원 택배 기사 등 이동 노동자 들 을 위한 폭염 대책 의 하나 로 경...</td>\n",
              "      <td>경기도 는 집배원 택배 기사 등 이동 노동자 들 을 위한 폭염 대책 의 하나 로 경...</td>\n",
              "      <td>[0, 8, 6, 9, 4]</td>\n",
              "      <td>[산은은 국내외 벤처생태계 저명인사들을 기조연설자로 초청해 국내 벤처생태계 활성화에...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21305</th>\n",
              "      <td>[여름 방학 을 맞 아 전국 의 국립 과 학관 에서 달 탐사 50 주년 과 국제 천...</td>\n",
              "      <td>여름 방학 을 맞 아 전국 의 국립 과 학관 에서 달 탐사 50 주년 과 국제 천문...</td>\n",
              "      <td>여름 방학 을 맞 아 전국 의 국립 과 학관 에서 달 탐사 50 주년 과 국제 천문...</td>\n",
              "      <td>[0, 1, 8, 10, 7]</td>\n",
              "      <td>[영주시는 외국인 근로자들의 향수를 달래고, 안정적인 한국생활 적응을 지원하기 위해...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21306 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a4aa08f-fa90-4713-991a-a7b97f5629ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a4aa08f-fa90-4713-991a-a7b97f5629ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a4aa08f-fa90-4713-991a-a7b97f5629ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 src_txt  \\\n",
              "0      [대한민국 5 G 홍보 대사 를 자처 한 문재 인 대통령 은 넓 고 체증 없 는 통...   \n",
              "1      [8 일 서울 올림픽 공원 K 아트홀, 지난 3 일 한국 이 세계 최초 로 5 세대...   \n",
              "2      [] 박원순 서울 시장 사진 이 8 일 고층 재 개발 재건축 관련 요구 에 작심 한...   \n",
              "3      [SK 주 와 미국 알파벳 구글 지주회사 의 간결 한 지배 구조 를 배워라, 기업 ...   \n",
              "4      [MBC 당신 이 믿 었 던 페이크 가 JTBC 손석희 대표 이사 의 동승자 논란 ...   \n",
              "...                                                  ...   \n",
              "21301  [울릉도 명이 가 유명세 를 탈 전망 이 다, 29 일 한국 을 공식 방문 한 도널...   \n",
              "21302  [경기도 수원 의 카페 투어 를 소재 로 한 토크 쇼 가 일본 의 수도 도쿄 에서 ...   \n",
              "21303  [산업은행 은 다음 달 23 24 일 이틀 간 서울 강남구 코엑스 에서 넥스트 라이...   \n",
              "21304  [경기도 는 집배원 택배 기사 등 이동 노동자 들 을 위한 폭염 대책 의 하나 로 ...   \n",
              "21305  [여름 방학 을 맞 아 전국 의 국립 과 학관 에서 달 탐사 50 주년 과 국제 천...   \n",
              "\n",
              "                                                 tgt_txt  \\\n",
              "0      대한민국 5 G 홍보 대사 를 자처 한 문재 인 대통령 은 넓 고 체증 없 는 통신...   \n",
              "1      지난 3 일 한국 이 세계 최초 로 5 세대 5 G 이동 통신 서비스 를 상용 화 ...   \n",
              "2      ] 박원순 서울 시장 사진 이 8 일 고층 재 개발 재건축 관련 요구 에 작심 한 ...   \n",
              "3      기업 지배 구조 개선 등 을 통해 높 은 수익 률 을 올리 는 것 을 목표 로 하 ...   \n",
              "4      MBC 당신 이 믿 었 던 페이크 가 JTBC 손석희 대표 이사 의 동승자 논란 진...   \n",
              "...                                                  ...   \n",
              "21301  울릉도 명이 가 유명세 를 탈 전망 이 다<q>29 일 한국 을 공식 방문 한 도널...   \n",
              "21302  경기도 와 경기 관광공사 는 지난 29 일 일본 도쿄 에서 경기도 골목 의 카페 와...   \n",
              "21303  산업은행 은 다음 달 23 24 일 이틀 간 서울 강남구 코엑스 에서 넥스트 라이즈...   \n",
              "21304  경기도 는 집배원 택배 기사 등 이동 노동자 들 을 위한 폭염 대책 의 하나 로 경...   \n",
              "21305  여름 방학 을 맞 아 전국 의 국립 과 학관 에서 달 탐사 50 주년 과 국제 천문...   \n",
              "\n",
              "                                     sum_sents_tokenized   sum_sents_idxes  \\\n",
              "0      문 대통령 은 8 일 서울 올림픽 공원 에서 열린 5 G 플러스 전략 발표 에 참석...   [1, 0, 9, 6, 4]   \n",
              "1      8 일 서울 올림픽 공원 K 아트홀\\n문재인 대통령 홍남기 부총리 겸 기획 재정부 ...  [0, 8, 10, 6, 1]   \n",
              "2      박 시장 은 이날 서울 시청 에서 열린 골목길 재생 시민 정책 대화 에 참석 해 과...   [1, 0, 4, 3, 5]   \n",
              "3      SK 주 와 미국 알파벳 구글 지주회사 의 간결 한 지배 구조 를 배워라\\nKB 운...   [0, 2, 1, 7, 9]   \n",
              "4      MBC 당신 이 믿 었 던 페이크 가 JTBC 손석희 대표 이사 의 동승자 논란 진...  [0, 8, 10, 9, 5]   \n",
              "...                                                  ...               ...   \n",
              "21301  29 일 한국 을 공식 방문 한 도널드 트럼프 대통령 의 청와대 친교 만찬 에 경북...   [1, 2, 0, 9, 8]   \n",
              "21302  경기도 와 경기 관광공사 는 지난 29 일 일본 도쿄 에서 경기도 골목 의 카페 와...   [1, 0, 8, 6, 9]   \n",
              "21303  산업은행 은 다음 달 23 24 일 이틀 간 서울 강남구 코엑스 에서 넥스트 라이즈...  [0, 7, 8, 10, 1]   \n",
              "21304  경기도 는 집배원 택배 기사 등 이동 노동자 들 을 위한 폭염 대책 의 하나 로 경...   [0, 8, 6, 9, 4]   \n",
              "21305  여름 방학 을 맞 아 전국 의 국립 과 학관 에서 달 탐사 50 주년 과 국제 천문...  [0, 1, 8, 10, 7]   \n",
              "\n",
              "                                             abstractive  \n",
              "0      [8일 서울에서 열린 5G플러스 전략발표에 참석한 문재인 대통령은 5G는 대한민국 ...  \n",
              "1      [지난 3일 한국이 세계 첫 5세대 이동통신 서비스를 보편화한 것을 축하하는 '코리...  \n",
              "2      [박원순 서울시장은 8일 서울시청에서 열린 '골목길 재생 시민 정책 대화'에 참석하...  \n",
              "3      [주주가치 포커스를 운용하는 KB자산운용이  SK와 알파벳(구글 지주회사)의 모범적...  \n",
              "4      [MBC ' 당신이 믿었던 페이크' 가 JTBC 손석희 대표의 '동승자 논란' 진실...  \n",
              "...                                                  ...  \n",
              "21301  [포항시는 오는 7월 당초 109개 노선 200대 운행에서 119개 노선 270대로...  \n",
              "21302  [경북울릉군 특산물인 명이장아찌가 2017년 한·미 정상회담 독도새우에 이어 29일...  \n",
              "21303  [지난 해 일본어 핸드 가이드 북인 '수원 카페북(마루마루 수원)이 투어리즘 엑스포...  \n",
              "21304  [산은은 국내외 벤처생태계 저명인사들을 기조연설자로 초청해 국내 벤처생태계 활성화에...  \n",
              "21305  [영주시는 외국인 근로자들의 향수를 달래고, 안정적인 한국생활 적응을 지원하기 위해...  \n",
              "\n",
              "[21306 rows x 5 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#데이터를 저장\n",
        "prun_data =pd.DataFrame(prun_data)\n",
        "pruning_data = pd.merge(data, prun_data,left_index=True, right_index=True)\n",
        "pruning_data.to_json(join(save_path, 'prun_data.json', orient = 'table')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yedd8qyj-YkD"
      },
      "source": [
        "#MATCHSUM\n",
        "- 예시 데이터를 사용할 경우 이 부분부터 실행하시면 됩니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsB1yY5fmh-U"
      },
      "source": [
        "### Class 및 함수 정의\n",
        "- CustomDataset (class : 데이터셋 정의)\n",
        "- custom_collate_fn (함수 : Trainer 내부에 collate_fn)\n",
        "- MatchSum (Class : 모델 정의)\n",
        "- train_model (함수 : train 파이프라인 정의)\n",
        "- test_model (함수 : test 파이프라인 정의)\n",
        "- ValidMetric (Class : evaluate metric 정의)\n",
        "- custom_compute_metrics (함수 : evaluate 파이프라인)\n",
        "- MatchRougeMetric (Class : Test metric 정의)\n",
        "- custom_compute_metrics_test (함수 : test 파이프라인)\n",
        "- MyTrainer (Class : huggingface Trainer custom)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#json 불러오기\n",
        "with open(data_path) as f: \n",
        "    prun_data = json.load(f)\n",
        "    prun_data = prun_data['data']\n",
        "    prun_data =pd.DataFrame(prun_data)"
      ],
      "metadata": {
        "id": "rylbMVYr8Ikk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###utils"
      ],
      "metadata": {
        "id": "s2QE6SidzlNv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vo57dIU56_ZU"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, input_data1:list,input_data2:list,input_data3:list) -> None:\n",
        "        self.X = input_data1\n",
        "        self.Y = input_data2\n",
        "        self.Z = input_data3\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.Y[index], self.Z[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xhDB_3Vkp0nW"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    - batch: list of dictionary \n",
        "    \n",
        "    한 배치 내 문장들을 tokenizing 한 후 텐서로 변환함. \n",
        "    이때, dynamic padding (즉, 같은 배치 내 토큰의 개수가 동일할 수 있도록, 부족한 문장에 [PAD] 토큰을 추가하는 작업)을 적용\n",
        "    \n",
        "    (input1,input2,input3, target) 딕셔너리 형태를 반환.\n",
        "    \"\"\"\n",
        "    max_len=180\n",
        "    max_len_text=512 #원래 512\n",
        "\n",
        "\n",
        "    text_list, cand_list, summ_list = [], [], []\n",
        "    token_cand = []\n",
        "    for input_text, input_cand, input_summ in batch:\n",
        "        text_list.append(input_text)\n",
        "        cand_list.append(input_cand)\n",
        "        summ_list.append(input_summ)\n",
        "    \n",
        "    tensorized_text = tokenizer(\n",
        "    text_list,\n",
        "    add_special_tokens=True,\n",
        "    padding=\"longest\",  # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "    truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "    max_length=max_len_text,\n",
        "    return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "    \n",
        "    for candidate in cand_list:\n",
        "        tensorized_cand = tokenizer(\n",
        "        candidate,\n",
        "        add_special_tokens=True,\n",
        "        padding='max_length',  # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가 (\"longest\")\n",
        "        truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "        max_length=max_len,\n",
        "        return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "        )\n",
        "\n",
        "        token_cand.append(tensorized_cand)\n",
        "\n",
        "    tensorized_summ = tokenizer(\n",
        "    summ_list,\n",
        "    add_special_tokens=True,\n",
        "    padding=\"longest\",  # 배치내 가장 긴 문장을 기준으로 부족한 문장은 [PAD] 토큰을 추가\n",
        "    truncation=True, # max_length를 넘는 문장은 이 후 토큰을 제거함\n",
        "    max_length=max_len,\n",
        "    return_tensors='pt' # 토크나이즈된 결과 값을 텐서 형태로 반환\n",
        "    )\n",
        "\n",
        "    #Trainer의 evaluate()를 위한 더미 변수\n",
        "    labels= torch.rand(len(tensorized_summ), 1)\n",
        "    \n",
        "    result ={'text_id':tensorized_text,'candidate_id': token_cand, 'summary_id':tensorized_summ,'labels':labels}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr8f2t8HOrd1",
        "outputId": "50e30bb5-4a2a-4fb8-d46c-70cebb1ac0b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train : 17044 17044\n",
            "validation : 2130 2130\n",
            "test : 2132 2132\n"
          ]
        }
      ],
      "source": [
        "#candidate개수 조정(20개->8개)\n",
        "prun_data['candidate_summary'] = prun_data['candidate_summary'].apply(lambda x: x[:8])\n",
        "prun_data['indices'] = prun_data['indices'].apply(lambda x: x[:8])\n",
        "\n",
        "#data split\n",
        "dataset_size = len(prun_data)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "validation_size = int(dataset_size * 0.1)\n",
        "test_size = dataset_size - train_size - validation_size\n",
        "\n",
        "#evaluate 부분에서 reset된 index가 필요\n",
        "#eval_train_dataset = prun_data[:train_size].reset_index(drop=True)\n",
        "eval_validation_dataset = prun_data[train_size:train_size+validation_size].reset_index(drop=True)\n",
        "eval_test_dataset = prun_data[train_size+validation_size:].reset_index(drop=True)\n",
        "\n",
        "# text, summary 문자열 합쳐주기\n",
        "prun_data['text'] = prun_data['text'].apply(lambda x: ' '.join(x))\n",
        "prun_data['summary'] = prun_data['summary'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "#train에 사용할 데이터셋\n",
        "train_dataset = prun_data[:train_size].reset_index(drop=True)\n",
        "validation_dataset = prun_data[train_size:train_size+validation_size].reset_index(drop=True)\n",
        "test_dataset = prun_data[train_size+validation_size:].reset_index(drop=True)\n",
        "\n",
        "print('train :',train_size, len(train_dataset))\n",
        "print('validation :',validation_size,len(validation_dataset))\n",
        "print('test :',test_size,len(test_dataset))\n",
        "\n",
        "#Dataset 설정\n",
        "train_set = CustomDataset(train_dataset['text'], train_dataset['candidate_summary'], train_dataset['summary'])\n",
        "validation_set = CustomDataset(validation_dataset['text'], validation_dataset['candidate_summary'], validation_dataset['summary'])\n",
        "test_set = CustomDataset(test_dataset['text'], test_dataset['candidate_summary'], test_dataset['summary'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model, train, test, Trainer"
      ],
      "metadata": {
        "id": "cypKft_Uzudr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mbzTVljc_LmK"
      },
      "outputs": [],
      "source": [
        "class MatchSum(nn.Module):\n",
        "    \n",
        "    def __init__(self, candidate_num, encoder, hidden_size=768):\n",
        "        super(MatchSum, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.candidate_num  = candidate_num\n",
        "        \n",
        "        self.encoder = BertModel.from_pretrained(encoder)\n",
        "\n",
        "    def forward(self, text_id, candidate_id, summary_id, labels):\n",
        "        \n",
        "        batch_size = text_id['input_ids'].size(0)\n",
        "\n",
        "        # get document embedding\n",
        "        outputs = self.encoder(input_ids=text_id['input_ids'], attention_mask=text_id['attention_mask'],\n",
        "                           token_type_ids=text_id['token_type_ids'])\n",
        "        \n",
        "        last_hidden_states = outputs[0]\n",
        "        doc_emb = last_hidden_states[:,0,:]\n",
        "\n",
        "        assert doc_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "        \n",
        "        # get summary embedding\n",
        "        outputs = self.encoder(input_ids=summary_id['input_ids'], attention_mask=summary_id['attention_mask'],\n",
        "                           token_type_ids=summary_id['token_type_ids'])\n",
        "        last_hidden_states = outputs[0]\n",
        "        summary_emb = last_hidden_states[:, 0, :]\n",
        "\n",
        "        assert summary_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "\n",
        "        # get summary score\n",
        "        summary_score = torch.cosine_similarity(summary_emb, doc_emb, dim=-1)\n",
        "\n",
        "        # get candidate embedding\n",
        "        cand_input_ids = []\n",
        "        cand_attention_mask = []\n",
        "        cand_token_type_ids = []\n",
        "\n",
        "        for candidate in candidate_id:\n",
        "            cand_input_ids.append(candidate['input_ids'])\n",
        "            cand_attention_mask.append(candidate['attention_mask'])\n",
        "            cand_token_type_ids.append(candidate['token_type_ids'])\n",
        "        # stack embeddings\n",
        "        cand_input_ids = torch.stack(cand_input_ids).view(-1,len(cand_input_ids[0][0]))\n",
        "        cand_attention_mask = torch.stack(cand_attention_mask).view(-1,len(cand_attention_mask[0][0]))\n",
        "        cand_token_type_ids = torch.stack(cand_token_type_ids).view(-1,len(cand_token_type_ids[0][0]))\n",
        "\n",
        "\n",
        "        outputs = self.encoder(input_ids=cand_input_ids, attention_mask=cand_attention_mask,\n",
        "                           token_type_ids=cand_token_type_ids)\n",
        "        last_hidden_states = outputs[0]\n",
        "        candidate_emb = last_hidden_states[:, 0, :].view(batch_size, self.candidate_num, self.hidden_size)  # [batch_size, candidate_num, hidden_size]        \n",
        "        \n",
        "        assert candidate_emb.size() == (batch_size, self.candidate_num, self.hidden_size)\n",
        "        \n",
        "        # get candidate score\n",
        "        doc_emb = doc_emb.unsqueeze(1).expand_as(candidate_emb)\n",
        "\n",
        "        score = torch.cosine_similarity(candidate_emb, doc_emb, dim=-1) # [batch_size, candidate_num]\n",
        "        assert score.size() == (batch_size, self.candidate_num)\n",
        "\n",
        "        #score는 문장단위 score , summary_score는 요약 단위 score\n",
        "        return {'score': score, 'summary_score': summary_score}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lpcmDoEsHmDo"
      },
      "outputs": [],
      "source": [
        "def train_model(train, valid,args):\n",
        "        \n",
        "    # load summarization datasets\n",
        "    print('Information of dataset is:')\n",
        "    train_dataset = train\n",
        "    valid_dataset = valid\n",
        "\n",
        "    # configure training\n",
        "    devices = [0]\n",
        "    params = {}\n",
        "    params['encoder']       = 'monologg/kobert'\n",
        "    params['candidate_num'] = 8\n",
        "    params['batch_size']    = 4 #32\n",
        "    params['accum_count']   = 2\n",
        "    params['max_lr']        = 2e-5\n",
        "    params['margin']        = 0.01\n",
        "    params['warmup_steps']  = 3000\n",
        "    params['n_epochs']      = 1\n",
        "    params['valid_steps']   = 1000\n",
        "    train_params=params\n",
        "\n",
        "    print('Devices is:')\n",
        "    print(devices)\n",
        "\n",
        "    # configure model\n",
        "    model = MatchSum(params['candidate_num'] , train_params['encoder'])\n",
        "\n",
        "    optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,\n",
        "    eps=1e-8)\n",
        "\n",
        "    assert 16 % len(devices) == 0\n",
        "    #train(model, train_set)\n",
        "    trainer = MyTrainer(model= model,args=args,train_dataset=train_dataset, eval_dataset=valid_dataset,\n",
        "                        compute_metrics= custom_compute_metrics,callbacks=[EarlyStoppingCallback(early_stopping_patience = 1)],\n",
        "                      optimizers=(optimizer,None),data_collator=custom_collate_fn,loss_name='MarginRankingLoss',\n",
        "                      margin = 0.01 )\n",
        "    print('Start training with the following hyper-parameters:')\n",
        "    print(train_params)\n",
        "    trainer.train()\n",
        "    \n",
        "    torch.save(model, join(model_path,'model.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Vp0WI7aqWoEZ"
      },
      "outputs": [],
      "source": [
        "def test_model(dataset, models_path,args_test,args):\n",
        "\n",
        "    print('Information of dataset is:')\n",
        "    print(dataset)\n",
        "    test_dataset = dataset\n",
        "    \n",
        "    # need 1 gpu for testing\n",
        "    device = [0]\n",
        "    \n",
        "    batch_size = 1\n",
        "        \n",
        "    # load model\n",
        "    model = torch.load(models_path)\n",
        "\n",
        "    optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,\n",
        "    eps=1e-8)\n",
        "\n",
        "    # configure testing\n",
        "    tester = MyTrainer(model= model,args=args_test,train_dataset=train_dataset, eval_dataset=test_dataset,\n",
        "                    compute_metrics= custom_compute_metrics_test,callbacks=[EarlyStoppingCallback(early_stopping_patience = 1)],\n",
        "                  optimizers=(optimizer,None),data_collator=custom_collate_fn,loss_name='MarginRankingLoss',\n",
        "                  margin = 0.01 )\n",
        "    tester.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1yJjyovgcU8o"
      },
      "outputs": [],
      "source": [
        "class MyTrainer(Trainer):\n",
        "    # loss_name 이라는 인자를 추가로 받아 self에 각인 시켜줍니다.\n",
        "    def __init__(self, loss_name, margin, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_name= loss_name # 각인!\n",
        "        self.margin = margin\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "\n",
        "        # config에 저장된 loss_name에 따라 다른 loss 계산 \n",
        "        if self.loss_name == 'MarginRankingLoss':\n",
        "            # lossname이 MarginRankingLoss 이면, custom_loss에 torch.nn.MarginRankingLoss()를 선언(?) 해줍니다.\n",
        "            custom_loss = torch.nn.MarginRankingLoss(self.margin)\n",
        "  \n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        score = outputs['score']\n",
        "        summary_score = outputs['summary_score']\n",
        "\n",
        "        # here is to avoid that some special samples will not go into the following for loop\n",
        "        ones = torch.ones(score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss = loss_func(score, score, ones)\n",
        "\n",
        "        # candidate loss\n",
        "        n = score.size(1)\n",
        "        for i in range(1, n):\n",
        "            pos_score = score[:, :-i]\n",
        "            neg_score = score[:, i:]\n",
        "            pos_score = pos_score.contiguous().view(-1)\n",
        "            neg_score = neg_score.contiguous().view(-1)\n",
        "            ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "            loss_func = torch.nn.MarginRankingLoss(self.margin * i)\n",
        "            TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "\n",
        "        # gold summary loss\n",
        "        pos_score = summary_score.unsqueeze(-1).expand_as(score)\n",
        "        neg_score = score\n",
        "        pos_score = pos_score.contiguous().view(-1)\n",
        "        neg_score = neg_score.contiguous().view(-1)\n",
        "        ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "        \n",
        "        return (TotalLoss, outputs) if return_outputs else TotalLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### metrics"
      ],
      "metadata": {
        "id": "D2ti-K35z9zr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kaX-t-UFRRhI"
      },
      "outputs": [],
      "source": [
        "#for evaluate\n",
        "class ValidMetric(BaseMetricLossFunction):  \n",
        "    def __init__(self, save_path, data, score=None):\n",
        "        super(ValidMetric, self).__init__()\n",
        "        #self._init_param_map(score=score)\n",
        " \n",
        "        self.save_path = save_path\n",
        "        self.data = data\n",
        "\n",
        "        self.top1_correct = 0\n",
        "        self.top6_correct = 0\n",
        "        #self.top10_correct = 0\n",
        "         \n",
        "        self.rouge = Rouge(\n",
        "            metrics=[\"rouge-n\", \"rouge-l\"],\n",
        "            max_n=2,\n",
        "            limit_length=True,\n",
        "            length_limit=1000,\n",
        "            length_limit_type=\"words\",\n",
        "            use_tokenizer=True,\n",
        "            apply_avg=True,\n",
        "            apply_best=False,\n",
        "            alpha=0.5,  # Default F1_score\n",
        "            weight_factor=1.2,)\n",
        "        self.ROUGE = 0.0\n",
        "        self.Error = 0\n",
        "\n",
        "        self.cur_idx = 0\n",
        "    \n",
        "    # an approximate method of calculating ROUGE\n",
        "    def fast_rouge(self, dec, ref):\n",
        "\n",
        "        if dec == '' or ref == '':\n",
        "            return 0.0\n",
        "        scores = self.rouge.get_scores(dec, ref)\n",
        "\n",
        "        return (scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f']) / 3\n",
        "\n",
        "    def evaluate(self, score):\n",
        "\n",
        "        batch_size = score.size(0)\n",
        "\n",
        "        #score에서 각 차원의 최대값 인덱스를 뽑아내는 것.\n",
        "        self.top1_correct += int(torch.sum(torch.max(score, dim=1).indices == 0))\n",
        "        self.top6_correct += int(torch.sum(torch.max(score, dim=1).indices <= 5))\n",
        "        self.top10_correct += int(torch.sum(torch.max(score, dim=1).indices <= 9))\n",
        "\n",
        "        # Fast ROUGE\n",
        "        for i in range(batch_size):\n",
        "            max_idx = int(torch.max(score[i], dim=0).indices)\n",
        "            if max_idx >= len(self.data.loc[self.cur_idx]['indices']):\n",
        "                self.Error += 1 # Check if the candidate summary generated by padding is selected\n",
        "                self.cur_idx += 1\n",
        "                continue\n",
        "            ext_idx = self.data.loc[self.cur_idx]['indices'][max_idx]\n",
        "            ext_idx.sort()\n",
        "            dec = []\n",
        "            ref = ''.join(self.data.loc[self.cur_idx]['summary'])\n",
        "            for j in ext_idx:\n",
        "                dec.append(self.data.loc[self.cur_idx]['text'][j])\n",
        "            dec = ''.join(dec)\n",
        "\n",
        "            self.ROUGE += self.fast_rouge(dec, ref)\n",
        "            self.cur_idx += 1\n",
        "\n",
        "    def get_metric(self, reset=True):\n",
        "\n",
        "        top1_accuracy = self.top1_correct / self.cur_idx\n",
        "        top6_accuracy = self.top6_correct / self.cur_idx\n",
        "        top10_accuracy = self.top10_correct / self.cur_idx\n",
        "\n",
        "        ROUGE = self.ROUGE / self.cur_idx\n",
        "\n",
        "\n",
        "        eval_result = {'top1_accuracy': top1_accuracy, 'top6_accuracy': top6_accuracy,'top10_accuracy': top10_accuracy, \n",
        "                       'Error': self.Error, 'ROUGE': ROUGE} \n",
        "       \n",
        "        with open(join(self.save_path, 'train_info.txt'), 'a') as f:\n",
        "            print('top1_accuracy = {}, top6_accuracy = {},top10_accuracy={},Error = {}, ROUGE = {}'.format(\n",
        "                top1_accuracy, top6_accuracy,top10_accuracy,self.Error, ROUGE),file=f)\n",
        "\n",
        "        if reset:\n",
        "            self.top1_correct = 0\n",
        "            self.top6_correct = 0\n",
        "            self.top10_correct = 0\n",
        "            self.ROUGE = 0.0\n",
        "            self.Error = 0\n",
        "            self.cur_idx = 0\n",
        "        return eval_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "f-MVtsi8AtwZ"
      },
      "outputs": [],
      "source": [
        "#for test\n",
        "class MatchRougeMetric(BaseMetricLossFunction):\n",
        "    def __init__(self, data, n_total,dec_path, save_name, score=None, save =False):\n",
        "        super(MatchRougeMetric, self).__init__()\n",
        "        self.data        = data\n",
        "        self.n_total     = n_total\n",
        "        self.cur_idx = 0\n",
        "        self.ext = []\n",
        "        self.start = time()\n",
        "        self.rouge = Rouge(\n",
        "            metrics=[\"rouge-n\", \"rouge-l\"],\n",
        "            max_n=2,\n",
        "            limit_length=True,\n",
        "            length_limit=1000,\n",
        "            length_limit_type=\"words\",\n",
        "            use_tokenizer=True,\n",
        "            apply_avg=True,\n",
        "            apply_best=False,\n",
        "            alpha=0.5,  # Default F1_score\n",
        "            weight_factor=1.2,)\n",
        "\n",
        "        self.path = dec_path\n",
        "        self.save_name = save_name\n",
        "        self.save = save\n",
        "\n",
        "    def evaluate(self, score):\n",
        "\n",
        "        batch_size = score.size(0)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            ext = int(torch.max(score[i], dim=0).indices) # batch_size = 1\n",
        "            self.ext.append(ext)\n",
        "            print('{}/{} ({:.2f}%) decoded in {} seconds\\r'.format(\n",
        "                  i, self.n_total, self.cur_idx/self.n_total*100, timedelta(seconds=int(time()-self.start))\n",
        "                ), end='')\n",
        "    \n",
        "    def save_output(self, dec_list, path, name):\n",
        "        with open(join(self.path, '{}.txt'.format(self.name)), 'w') as f:\n",
        "            print(self.dec_list, file=f)\n",
        "\n",
        "    def get_metric(self, reset=True):\n",
        "        R_1_sum = 0\n",
        "        R_2_sum = 0\n",
        "        R_L_sum = 0\n",
        "        print('\\nStart calculate each text !!!')\n",
        "        for i, ext in enumerate(self.ext):\n",
        "            sent_ids = self.data.loc[i]['indices'][ext]\n",
        "            dec=[]\n",
        "            for j in sent_ids:\n",
        "                dec.append(self.data.loc[i]['text'][j])#self.cur_idx\n",
        "\n",
        "            #저장하는 메소드 만들기\n",
        "            if self.save == True:\n",
        "                self.save_output(dec, self.path, self.save_name)           \n",
        "            \n",
        "            dec = ''.join(dec)\n",
        "            ref = self.data.loc[i]['summary']\n",
        "        \n",
        "            self.cur_idx += 1\n",
        "\n",
        "            R_1, R_2, R_L = self.eval_rouge(dec, ref)\n",
        "        \n",
        "            R_1_sum += R_1\n",
        "            R_2_sum += R_2\n",
        "            R_L_sum += R_L\n",
        "        \n",
        "        R_1_mean = R_1_sum/self.cur_idx   #self.n_total\n",
        "        R_2_mean = R_2_sum/self.cur_idx \n",
        "        R_L_mean = R_L_sum/self.cur_idx \n",
        "\n",
        "        print('Start evaluating ROUGE score !!!')\n",
        "        \n",
        "        eval_result = {'ROUGE-1': R_1_mean, 'ROUGE-2': R_2_mean, 'ROUGE-L':R_L_mean} \n",
        "        \n",
        "        if reset == True:\n",
        "            self.cur_idx = 0\n",
        "            self.ext = []\n",
        "            self.data = []\n",
        "            self.start = time()\n",
        "\n",
        "        return eval_result\n",
        "        \n",
        "    def eval_rouge(self, dec, ref):\n",
        "        if dec == '' or ref == '':\n",
        "            return 0.0\n",
        "        scores = self.rouge.get_scores(dec, ref)\n",
        "        R_1 = scores['rouge-1']['f']\n",
        "        R_2 = scores['rouge-2']['f']\n",
        "        R_L = scores['rouge-l']['f']\n",
        "\n",
        "        return R_1, R_2, R_L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JEPXPlpFzBpb"
      },
      "outputs": [],
      "source": [
        "#for evaluate - compute_metrics\n",
        "def custom_compute_metrics(pred):\n",
        "    preds = pred.predictions[0]\n",
        "    preds = torch.Tensor(preds)\n",
        "    val_metric = ValidMetric(save_path='/content/drive/MyDrive/matchsum/savepoint', data=eval_validation_dataset)\n",
        "    val_metric.evaluate(preds)\n",
        "    eval_result = val_metric.get_metric()\n",
        "    return eval_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JxPe-WRPdVpD"
      },
      "outputs": [],
      "source": [
        "#for test - compute_metrics\n",
        "def custom_compute_metrics_test(pred):\n",
        "    preds = pred.predictions[0]\n",
        "    preds = torch.Tensor(preds)\n",
        "    test_metric = MatchRougeMetric(data=eval_test_dataset, n_total = len(eval_test_dataset),dec_path=dec_path, save_name='save1')\n",
        "    test_metric.evaluate(preds)\n",
        "    eval_result = test_metric.get_metric()\n",
        "    return eval_result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### set Trainer arguments"
      ],
      "metadata": {
        "id": "pTkcqMzS0DuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#arguments setting\n",
        "\n",
        "args_train = TrainingArguments(\n",
        "    # checkpoint\n",
        "    output_dir=output_dir,\n",
        "\n",
        "    # Model Save & Load\n",
        "    save_strategy= 'epoch', #\n",
        "    load_best_model_at_end=True, # train 종료시 best model 로드할지 여부\n",
        "\n",
        "    # Dataset\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "\n",
        "    # Evaluation \n",
        "    evaluation_strategy = \"epoch\",# 각 epoch 마지막에 평가\n",
        "\n",
        "    # Randomness\n",
        "    seed=42,\n",
        "\n",
        "    #for ealry stopping callback\n",
        "    metric_for_best_model = 'ROUGE',\n",
        "\n",
        "    warmup_steps=1000,               # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "args_test = TrainingArguments(\n",
        "    # checkpoint\n",
        "    output_dir=output_dir,\n",
        "\n",
        "    # Model Save & Load\n",
        "    save_strategy= 'epoch',\n",
        "    load_best_model_at_end=True, # train 종료시 best model 로드할지 여부\n",
        "\n",
        "    # Dataset\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=1,\n",
        "    \n",
        "    metric_for_best_model ='ROUGE-1',\n",
        "    \n",
        "    # Evaluation \n",
        "    evaluation_strategy = \"epoch\",# 각 epoch 마지막에 평가\n",
        "\n",
        "    # Randomness\n",
        "    seed=42,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8jqRZha8wvB",
        "outputId": "a2a3c2ee-cdf1-413e-d975-f1cf5f233b41"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###실행"
      ],
      "metadata": {
        "id": "2Y01dcRu0K0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 train\n",
        "train_model(train_set, validation_set, args_train)"
      ],
      "metadata": {
        "id": "pXt6ml52xyr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWzHyZ47Y4LF"
      },
      "outputs": [],
      "source": [
        "#모델 test\n",
        "test_model(test_set, model_path,args_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8evtzTKcF8lq",
        "yedd8qyj-YkD",
        "s2QE6SidzlNv",
        "cypKft_Uzudr",
        "D2ti-K35z9zr",
        "pTkcqMzS0DuA",
        "2Y01dcRu0K0x"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}